{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinct-oriental",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The PhraseMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cecf281-0e0e-4540-8f16-b769a75b8a5a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607b569-41d6-46e7-a630-285a0d6c33db",
   "metadata": {},
   "source": [
    "Another rules-based component built into spaCy is the PhraseMatcher. Like the Matcher, the PhraseMatcher does not sit inside a spaCy pipeline. It does not, therefore, align with a spaCy extension, such as `doc.ents`, like the EntityRuler does. Instead, it is meant to run over a Doc container, just like the Matcher. Unlike the Matcher, however, the PhraseMatcher does not function a sequence of linguistic features at the token level, rather it is focused on matching at the phrase level.\n",
    "\n",
    "In practice, you would use the Matcher when you need to rely on a sequence of linguistic features at the token level to extract data. This is powerful, but can sometimes be difficult to write robust patterns to match all instances of a the patterns you wish to match. The PhraseMatcher, on the other hand, should be used when you know relatively well how the data will appear in a text. It is easier to use the PhraseMatcher, but it is not as dynamic as the Matcher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee79696-b2e9-4f8c-8991-c20abc91a99d",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa5795-606b-46de-8700-20cb3e6d2a1b",
   "metadata": {},
   "source": [
    "As with the Matcher, it is best to see the PhraseMatcher in action with a basic example. First, let's import the `PhraseMatcher` class and load up the default small English pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "palestinian-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "294c4715-9e8e-4498-a6eb-3aa42003a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e0081-bbb6-4473-834e-2f49b3e67086",
   "metadata": {},
   "source": [
    "Now, let's consider a basic example. Let's consider the text below. Here, we wish to find and extract the instances where Harry Potter appears in the text. Harry appears in four different ways in the text: 1) Harry Potter, 2) Harry, 3) Potter, and 4) The Boy who Lived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74431718-8348-409d-baf4-f908aad71f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Harry Potter was the main character in the book.\n",
    "Harry was a normal boy who discovered he was a wizard.\n",
    "Ultimately, Potter goes to Hogwarts.\n",
    "He is also known as the Boy who Lived.\n",
    "The Boy who Lived has an enemy named Voldemorte who is known as He who Must not be Named.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ad4e1c3-a528-4f4b-9525-06aa54997389",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adbc0198-c796-4da7-b725-c08982e05857",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"HARRY_POTTER\", [nlp(\"Harry Potter\"), nlp(\"Harry\"), nlp(\"Potter\"), nlp(\"the Boy who Lived\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ab2bc5d-fc09-4b26-8781-104284e6578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111e9fe-56f0-48d2-a470-fcbcf83766e9",
   "metadata": {},
   "source": [
    "Again, we will create our matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "806cbbd0-3633-424a-be0b-9fe6f7f1cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12325ba-26f7-41a8-b17d-0a6257f6fb78",
   "metadata": {},
   "source": [
    "Let's iterate over our matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fbc9e967-43df-4b5f-823d-bebc087904b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12243270181114079557, 1, 2)\n",
      "(12243270181114079557, 1, 3)\n",
      "(12243270181114079557, 2, 3)\n",
      "(12243270181114079557, 12, 13)\n",
      "(12243270181114079557, 27, 28)\n",
      "(12243270181114079557, 38, 42)\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620b3b7-6ce6-4c3a-b743-e88c326c66ce",
   "metadata": {},
   "source": [
    "And now let's iterate over our matches and grab a bit more data, including the token spans and the sentence in which a match was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4951207f-eab9-4912-bc05-e16b4e15cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRY_POTTER Harry\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n",
      "HARRY_POTTER Harry Potter\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n",
      "HARRY_POTTER Potter\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n",
      "HARRY_POTTER Harry\n",
      "Sentence: Harry was a normal boy who discovered he was a wizard.\n",
      "\n",
      "HARRY_POTTER Potter\n",
      "Sentence: Ultimately, Potter goes to Hogwarts.\n",
      "\n",
      "HARRY_POTTER the Boy who Lived\n",
      "Sentence: He is also known as the Boy who Lived.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    lexeme, start, end = match\n",
    "    print(nlp.vocab[lexeme].text, doc[start:end])\n",
    "    print(f\"Sentence: {doc[start].sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716cfd9-eacb-4632-b441-0c1ed2a7e8ea",
   "metadata": {},
   "source": [
    "As we can tel, the results are good, but we are missing one case. The second example of `boy who lived` was not grabbed because `The` was not capitalized. We can account for this by changing the main attribute of the PhraseMatcher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ca7d7-c16f-4ab8-a29a-52eeb5109dcc",
   "metadata": {},
   "source": [
    "## Setting a Custom Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc361821-0d66-48e7-a2d4-4de82f044acf",
   "metadata": {},
   "source": [
    "Unlike the Matcher, the PhraseMatcher does not let us control how it reads each individual token in the pattern. The way the PhraseMatcher parses the phrase is as the sequence level. By default, the PhraseMatcher reads the entire pattern as `ORTH`, or raw text. In other words, it must be a precise match in order to be flagged and extracted. In some instances, however, it may be important for a pattern to be not just raw text, but also in all forms, both uppercase and lowercase. This is particularly important for phrases, like `the boy who lived`, where the word `the` may be capitalized if it is at the start of a sentence. In these instances, we can change the main way the PhraseMatcher works by using the `attr` argument. By using `attr=\"LOWER\"`, we can make our PhraseMatcher pattern case-agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6fd4af43-ccb0-4738-899e-de384a8470f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6377a441-f77f-4752-b0d7-d819a0289eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"HARRY_POTTER\", [nlp(\"Harry Potter\"), nlp(\"Harry\"), nlp(\"Potter\"), nlp(\"the Boy who Lived\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3b6feffa-e1ed-4e92-acee-24afc50a8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "18859d98-62d3-4462-a3cf-3bac8a020eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0db5d691-ee2f-42a0-8927-60a327ef8bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRY_POTTER Harry\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n",
      "HARRY_POTTER Harry Potter\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n",
      "HARRY_POTTER Potter\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n",
      "HARRY_POTTER Harry\n",
      "Sentence: Harry was a normal boy who discovered he was a wizard.\n",
      "\n",
      "HARRY_POTTER Potter\n",
      "Sentence: Ultimately, Potter goes to Hogwarts.\n",
      "\n",
      "HARRY_POTTER the Boy who Lived\n",
      "Sentence: He is also known as the Boy who Lived.\n",
      "\n",
      "HARRY_POTTER The Boy who Lived\n",
      "Sentence: The Boy who Lived has an enemy named Voldemorte who is known as He who Must not be Named.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    lexeme, start, end = match\n",
    "    print(nlp.vocab[lexeme].text, doc[start:end])\n",
    "    print(f\"Sentence: {doc[start].sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d542a-ec6e-4c4a-96a4-8ea8ad0d30d5",
   "metadata": {},
   "source": [
    "Notice that now, we have grabbed all ways the phrase `the boy who lived` is expressed in our text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b04c38c-8a9b-4111-bf97-e0a8c4c0809a",
   "metadata": {},
   "source": [
    "## Adding a Function with `on_match`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5d3e6-3432-4a43-8eac-939037ff9ac0",
   "metadata": {},
   "source": [
    "In production, it can sometimes be difficult to deploy a spaCy-based solution that requires pasting a for loop each time you want to iterate over the results. Usually, you want to automate certain tasks so that when a match is found, some event occurs in your code. The PhraseMatcher allows you to pass an extra argument to your patterns: `on_match`. This keyword argument will take a function which will receive four arguments from the PhraseMatcher: `matcher` (the PhraseMatcher), `doc` (the doc container that the PhraseMatcher just passed over), `id`, and `matches` (the resulting matches from the PhraseMatcher).\n",
    "\n",
    "Let's create a basic function that will iterate over each match and print off the match, its label, and the sentence in which it was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fd07b2ba-9b44-4a01-9d71-f6c5f45c259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_match(matcher, doc, id, matches):\n",
    "    for match in matches:\n",
    "        lexeme, start, end = match\n",
    "        print(nlp.vocab[lexeme].text, doc[start:end])\n",
    "        print(f\"Sentence: {doc[start].sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6d7e7-57ba-48f6-92b2-9d7ee5287a0d",
   "metadata": {},
   "source": [
    "Just as before, we will create our PhraseMatcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2a9a9422-42f8-48ab-bc91-c61b46c2affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f38b80a-e745-4ea3-beb1-37d19981ea3c",
   "metadata": {},
   "source": [
    "This time, however, when we add our patterns to the PhraseMatcher, we will also add the keyword argument `on_match` that will point to the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aa4f7e58-c5f0-4b61-8bad-b640a9955ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"HARRY_POTTER\", [nlp(\"Harry Potter\")], on_match=on_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86f906-5643-4613-ae68-b5bff7f1c395",
   "metadata": {},
   "source": [
    "All that is left to do is then create the Doc container from the text and then run the PhraseMatcher over the Doc container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e696f63e-1923-4edd-aec5-ad6151f8a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRY_POTTER Harry Potter\n",
      "Sentence: Harry Potter was the main character in the book.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9a83b-0df4-4b7e-b013-9d583367f656",
   "metadata": {},
   "source": [
    "Just like the PhraseMatcher, the Matcher also can take the `on_match` keyword argument."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
