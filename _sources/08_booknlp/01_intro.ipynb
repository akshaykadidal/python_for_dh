{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-former",
   "metadata": {},
   "source": [
    "# <center>Introduction to BookNLP</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-voice",
   "metadata": {},
   "source": [
    "## What is BookNLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-delicious",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/booknlp/booknlp\">BookNLP</a> is a new Python library created by <a href=\"https://github.com/dbamman\">David Bamman</a>. It was originally created as a Java library in 2014 under the same name, <a href=\"https://github.com/dbamman/book-nlp\">BookNLP</a> by David Bamman, Ted Underwood, and Noah Smith (see, David Bamman, Ted Underwood and Noah Smith, \"A Bayesian Mixed Effects Model of Literary Character,\" ACL 2014). While Java is a powerful coding language, both in speed and ease-of-use, not many digital humanists code in Java primarily. I suspect (I want to emphasize I could be wrong) the reason for the Python library was to address the larger Python-coding community both in general and specifically within the digital humanities. This textbook will deal strictly with the Python library.\n",
    "\n",
    "In the documentation, Bamman states:\n",
    "\n",
    "\"BookNLP is a natural language processing pipeline that scales to books and other long documents (in English), including:\n",
    "\n",
    "- Part-of-speech tagging\n",
    "- Dependency parsing\n",
    "- Entity recognition\n",
    "- Character name clustering (e.g., \"Tom\", \"Tom Sawyer\", \"Mr. Sawyer\", \"Thomas Sawyer\" -> TOM_SAWYER) and coreference resolution\n",
    "- Quotation speaker identification\n",
    "- Supersense tagging (e.g., \"animal\", \"artifact\", \"body\", \"cognition\", etc.)\n",
    "- Event tagging\n",
    "- Referential gender inference (TOM_SAWYER -> he/him/his)\"\n",
    "\n",
    "Unlike its predecessor, the Java library, the Python library leverages the Python NLP library, <a href=\"https://spacy.io/\">spaCy</a>, and the Python Transformer library from <a href=\"https://huggingface.co/\">HuggingFace</a>, rather than Stanford, to perform many of these tasks. In the last few years, spaCy has proven itself as a dominate force within the NLP community, outperforming many of its predecessors in accuracy and in its ability to perform at scale. HuggingFace is a library that allows one to create and leverage large and powerful transformer language models. It also allows users to store these models in the cloud which are too large to store within GitHub or other comparable repositories. I have two textbooks on <a href=\"http://spacy.pythonhumanities.com/intro.html\">spaCy</a>, both for the library generally, and one for <a href=\"http://ner.pythonhumanities.com/intro.html\">named entity recognition</a>, specifically.\n",
    "\n",
    "BookNLP delivers in all the things it sets out to do, though it currently only supports English. Because it leverages transformer models, BookNLP's results can generalize well on non-standard English. I have seen it perform quite well with the South African dialect of English, by correctly identifying out-of-vocabulary (OOV) words, specifically the correct labeling of Afrikaans words for minivans as vehicles.\n",
    "\n",
    "Although only available in English as if March 2022, there are clear plans to expand the library to include Spanish, Japanese, Russian, and Germran, as per their recent <a href=\"https://securegrants.neh.gov/publicquery/main.aspx?f=1&gn=HAA-271654-20\">NEH grant</a>, awarded in September 2020.\n",
    "\n",
    "Throughout this book, we will use BookNLP to do what it was intended to do, analyze large fictional works. We will also, however, push it to analyze larger historical documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-christian",
   "metadata": {},
   "source": [
    "## Why Books and Larger Documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-pricing",
   "metadata": {},
   "source": [
    "Both the documentation and this textbook emphasize the word <i>large</i> here. The reason? Because most language models do not perform well with larger documents. Old RNN-based language models had a hard time remembering earlier words and while newer transformer-based models, such as BERT, have a larger memory and can look forwards and backwards, the size of the input they can take in is only 512 words. For larger documents, therefore, different solutions (and libraries) should be considered. This is where BookNLP comes in. It also addresses several problems associated with books and larger documents, such as:\n",
    "\n",
    "- Characters (and people) are referenced by different names. BookNLP solves this problem with name clustering and coreference resolution. This is a task in NLP where we try and find all uses a name and correctly assign them to the same identifier, such as Harry, Harry Potter, and Mr. Harry Potter all being the same person, Harry Potter.\n",
    "- An adjacent problem is referential gender inferencing. Like coreference resolution, often times in a book or larger document, a person will be referred to as a pronoun. This is where referential gender inferencing comes in. This allows a user to correctly assign the antecedent or postcedent to the correct pronoun. When done successfully, this also allows you to make decisions about the gender of the character or person based on how they are referenced in the text. Because this task is so delicate, given the delicate nature of assigning gender, BookNLP fortunately gives users the data with each pronoun used to reference a character and also includes non-binary pronouns.\n",
    "- Another issue is quotation speaker identification. This is when we need to understand who is speaking, so that we can correctly link characters to their dialogues. It is possible to do this with spaCy, but it is extremely difficult to do well. BookNLP does a remarkable job of handling this problem and it does it with a fair degree of accuracy, from what I have seen.\n",
    "- Event tagging is another key issue with longer documents and books. There are machine learning models that find events and you can easily cultivate a list of domain-specific events to improve a pipeline, but for BookNLP event is defined more broadly. From my experience, it is more based around key actions, rather than named events (as it is in named entity recognition). This has a tangential benefit known as triple extraction. In my opinion, it might be a bit better to view BookNLP events through this lens. Triple extraction is when we try and extract three pieces of information, such as (Actor, Action, Recipient) or (Actor, IS, Something). With these types of tuples, we can construct a knowledge tree about a corpus fairly easily. This a very challenging problem in NLP because triple extraction can be very domain-specific. BookNLP provides a great starting place for triple extraction with its events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-colorado",
   "metadata": {},
   "source": [
    "## How to Install BookNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-match",
   "metadata": {},
   "source": [
    "If you are using Linux (and I believe Mac - for Mac M1, see below), installation will be easy. Use pip install booknlp. You can opt to create a custom environment (recommended but not necessary). If you are using Windows, however, as of March 3 2022, you will need to do a few additional steps which I have documented in this video below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "first-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjbmattingly/anaconda3/envs/python-textbook/lib/python3.9/site-packages/IPython/core/display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3l5ERF3QX0M\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3l5ERF3QX0M\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7807c-1482-4b7b-9877-90c9d6f7e860",
   "metadata": {},
   "source": [
    "## How to Install BookNLP on Mac M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6808e34-a93a-42f2-834c-1613de939bc1",
   "metadata": {},
   "source": [
    "This section was kindly written by Joel Lee, Fellow at the United States Holocaust Memorial Museum.\n",
    "\n",
    "When running on M1, you may run into a “zsh: illegal hardware instruction” when trying to run spacy or booknlp commands after pip installing booknlp, or you may run into some dependency errors when trying to pip install booknlp. This is my workaround for that, where we download the dependencies (spacy, tensorflow, pytorch, and transformers) stated in the setup.py manually and then running pip install booknlp without its dependencies.\n",
    "\n",
    "- First, if you do not already have an Anaconda or miniconda for your local Python development, start with a conda install, we will follow this guide to use miniforge.\n",
    "    - https://www.mrdbourke.com/setup-apple-m1-pro-and-m1-max-for-machine-learning-and-data-science/\n",
    "        - Instant Download Link for Miniforge3 (Conda installer) for macOS arm64 chips (M1, M1 Pro, M1 Max).\n",
    "        - `chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh`\n",
    "        - `sh ~/Downloads/Miniforge3-MacOSX-arm64.sh`\n",
    "        - `source ~/miniforge3/bin/activate`\n",
    "- With your existing or newly installed conda environment installed, continue in your Terminal or Anaconda Prompt session.\n",
    "    - To ensure the conda environment you will create uses the MacOS native `osx-arm64` version of Python packages for your M1 Apple Silicon computer, execute this command in your Terminal or Anaconda Prompt session before following the rest of this recipe.\n",
    "        - `conda env config vars set CONDA_SUBDIR=osx-arm64`\n",
    "    - Now create and activate a new conda virtual environment that you will use for the BookNLP course:\n",
    "        - `conda create -n booknlp python=3.8`\n",
    "        - `conda activate booknlp`\n",
    "- Installing tensorflow.\n",
    "    - `conda install -c apple tensorflow-deps`\n",
    "    - `python -m pip install tensorflow-macos`\n",
    "    - `python -m pip install tensorflow-metal`\n",
    "- Installing spacy.\n",
    "    - `conda install -c conda-forge spacy`\n",
    "- Installing transformers.\n",
    "    - `conda install transformers` OR\n",
    "    - `pip install transformers`\n",
    "- Installing pytorch.\n",
    "    - `conda install -c pytorch pytorch` OR, if this gives you installation troubles, try\n",
    "    - `conda install -c conda-forge pytorch`\n",
    "- Now if we were to run `pip install booknlp` we would very likely get a conflicting dependency error or ResolutionImpossible error between booknlp and tensorflow. Fortunately, because we have installed the dependencies ourselves, we can run the pip install _without_ including the already installed dependencies.\n",
    "    - `pip install --no-dependencies booknlp` (Note the option parameter starts with two-dash characters.)\n",
    "- Now we can download the spacy pipeline and should be able to follow the rest of the booknlp repo.\n",
    "    - `python -m spacy download en_core_web_sm`\n",
    "\n",
    "Congratulations! Your M1-based Macintosh should now be ready to use as you take the BookNLP course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f3416",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef1590-6d9c-41c7-9339-3c2ba1cf10fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
