{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-former",
   "metadata": {},
   "source": [
    "# Introduction to BookNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-voice",
   "metadata": {},
   "source": [
    "## What is BookNLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-delicious",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/booknlp/booknlp\">BookNLP</a> is a new Python library created by <a href=\"https://github.com/dbamman\">David Bamman</a>. It was originally created as a Java library in 2014 under the same name, <a href=\"https://github.com/dbamman/book-nlp\">BookNLP</a> by David Bamman, Ted Underwood, and Noah Smith (see, David Bamman, Ted Underwood and Noah Smith, \"A Bayesian Mixed Effects Model of Literary Character,\" ACL 2014). While Java is a powerful coding language, both in speed and ease-of-use, not many digital humanists code in Java primarily. I suspect (I want to emphasize I could be wrong) the reason for the Python library was to address the larger Python-coding community both in general and specifically within the digital humanities. This textbook will deal strictly with the Python library.\n",
    "\n",
    "In the documentation, Bamman states:\n",
    "\n",
    "\"BookNLP is a natural language processing pipeline that scales to books and other long documents (in English), including:\n",
    "\n",
    "- Part-of-speech tagging\n",
    "- Dependency parsing\n",
    "- Entity recognition\n",
    "- Character name clustering (e.g., \"Tom\", \"Tom Sawyer\", \"Mr. Sawyer\", \"Thomas Sawyer\" -> TOM_SAWYER) and coreference resolution\n",
    "- Quotation speaker identification\n",
    "- Supersense tagging (e.g., \"animal\", \"artifact\", \"body\", \"cognition\", etc.)\n",
    "- Event tagging\n",
    "- Referential gender inference (TOM_SAWYER -> he/him/his)\"\n",
    "\n",
    "Unlike its predecessor, the Java library, the Python library leverages the Python NLP library, <a href=\"https://spacy.io/\">spaCy</a>, and the Python Transformer library from <a href=\"https://huggingface.co/\">HuggingFace</a>, rather than Stanford, to perform many of these tasks. In the last few years, spaCy has proven itself as a dominate force within the NLP community, outperforming many of its predecessors in accuracy and in its ability to perform at scale. HuggingFace is a library that allows one to create and leverage large and powerful transformer language models. It also allows users to store these models in the cloud which are too large to store within GitHub or other comparable repositories.\n",
    "\n",
    "BookNLP delivers in all the things it sets out to do, though it currently only supports English. Because it leverages transformer models, BookNLP's results can generalize well on non-standard English. I have seen it perform quite well with the South African dialect of English, by correctly identifying out-of-vocabulary (OOV) words, specifically the correct labeling of Afrikaans words for minivans as vehicles.\n",
    "\n",
    "Although only available in English as if March 2022, there are clear plans to expand the library to include Spanish, Japanese, Russian, and Germran, as per their recent <a href=\"https://securegrants.neh.gov/publicquery/main.aspx?f=1&gn=HAA-271654-20\">NEH grant</a>, awarded in September 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-christian",
   "metadata": {},
   "source": [
    "## Why Books and Larger Documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-pricing",
   "metadata": {},
   "source": [
    "Both the documentation and this textbook emphasize the word <i>large</i> here. The reason? Because most language models do not perform well with larger documents. Old RNN-based language models had a hard time remembering earlier words and while newer transformer-based models, such as BERT, have a larger memory and can look forwards and backwards, the size of the input they can take in is only 512 words. For larger documents, therefore, different solutions (and libraries) should be considered. This is where BookNLP comes in. It also addresses several problems associated with books and larger documents, such as:\n",
    "\n",
    "- Characters (and people) are referenced by different names. BookNLP solves this problem with name clustering and coreference resolution. This is a task in NLP where we try and find all uses a name and correctly assign them to the same identifier, such as Harry, Harry Potter, and Mr. Harry Potter all being the same person, Harry Potter.\n",
    "- An adjacent problem is referential gender inferencing. Like coreference resolution, often times in a book or larger document, a person will be referred to as a pronoun. This is where referential gender inferencing comes in. This allows a user to correctly assign the antecedent or postcedent to the correct pronoun. When done successfully, this also allows you to make decisions about the gender of the character or person based on how they are referenced in the text. Because this task is so delicate, given the delicate nature of assigning gender, BookNLP fortunately gives users the data with each pronoun used to reference a character and also includes non-binary pronouns.\n",
    "- Another issue is quotation speaker identification. This is when we need to understand who is speaking, so that we can correctly link characters to their dialogues. It is possible to do this with spaCy, but it is extremely difficult to do well. BookNLP does a remarkable job of handling this problem and it does it with a fair degree of accuracy, from what I have seen.\n",
    "- Event tagging is another key issue with longer documents and books. There are machine learning models that find events and you can easily cultivate a list of domain-specific events to improve a pipeline, but for BookNLP event is defined more broadly. From my experience, it is more based around key actions, rather than named events (as it is in named entity recognition). This has a tangential benefit known as triple extraction. In my opinion, it might be a bit better to view BookNLP events through this lens. Triple extraction is when we try and extract three pieces of information, such as (Actor, Action, Recipient) or (Actor, IS, Something). With these types of tuples, we can construct a knowledge tree about a corpus fairly easily. This a very challenging problem in NLP because triple extraction can be very domain-specific. BookNLP provides a great starting place for triple extraction with its events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-colorado",
   "metadata": {},
   "source": [
    "## How to Install BookNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-match",
   "metadata": {},
   "source": [
    "If you are using Linux, installation will be easy. Use\n",
    "\n",
    "```pip install booknlp```\n",
    "\n",
    "You can opt to create a custom environment (recommended but not necessary). If you are using Windows, however, as of March 3 2022, you will need to do a few additional steps which I have documented in this video below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-scott",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3l5ERF3QX0M\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3l5ERF3QX0M\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f3416",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef1590-6d9c-41c7-9339-3c2ba1cf10fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
