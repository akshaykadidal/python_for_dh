{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e804c4a-d233-4cd3-a0f2-e973af937cde",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a805ff-3986-4916-951c-c65da2065fa0",
   "metadata": {},
   "source": [
    "I designed this textbook to serve two functions. First, it will function as a primer to Python for humanists (or, more generally, those without coding experience or a background in computer science). In this regard, readers will acquire a basic understanding of necessary background information, such as data and data structures, as well as the basics of Python.\n",
    "\n",
    "Second, this textbook is designed to not only provide the reader with a basic understanding of Python and how to use it, but how to apply it specifically to humanities-based problems. The book particularly explores applying Python in data analysis with Pandas, natural language processing (NLP) with spaCy, topic modeling with Gensim (for LDA topic modeling) and Top2Vec (for modern topic modeling).\n",
    "\n",
    "While this book will provide a cursory overview of Python, it will not provide you with all aspects of the language or how to use it. This book is designed to get you up and running with Python as quickly as possible, giving you the essential tools you need to read and write in the language to solve tasks quickly and effectively. This textbook is not designed for computer scientists who wish to explore the depths of the programming language, rather humanists who need Python to automate certain tasks in their workflow. Explanation of certain aspects of the language are, therefore, kept to a minimum.\n",
    "\n",
    "It is important to note that this book is entirely designed in Jupyter Notebooks (discussed in Part One, Chapter One). This means that you will not receive exposure to the command line or receive proper training in writing a Python script (.py) file. These are useful skills to have, but not necessary to begin working with data. Despite these limitations of the textbook, this book will give you the tools necessary to begin learning on your own.\n",
    "\n",
    "Part One of the textbook introduces the reader to the basics of Python. Here, we will learn about the basics of coding (Chapter 1) and the essentials about data and data structures and how to work with them via Python (Chapter 2). These chapters will provide the necessary foundation for exploring key programming basics, such as loops and conditionals (Chapter 3), functions, classes, and libraries (Chapter 4), and working with external data, such as text files and JSON (Chapter 5). The final chapter of Part One will introduce the reader to the basics of web scraping and working with data found on the web.\n",
    "\n",
    "After Part One, the reader will have a basic understanding of Python, its syntax, and be able to begin working with data to design projects. The remainder of the textbook is designed to reinforce all of the skills acquired in Part One. Each of the following parts of the textbook will also introduce the reader to the key libraries associated with their respective subjects.\n",
    "\n",
    "In Part Two, we will take a deep dive into data analysis. In Python, the essential library for working with data, specifically tabular data, is Pandas. We will learn the basics while working with the open-source Titanic dataset. By the end of Part Two, the reader will have a basic understanding of Pandas and be able to leverage it in their own projects.\n",
    "\n",
    "Part Three shifts focus to text analysis. Here, we will learn about natural language processing (NLP) and how to use Python and the library spaCy to engage in NLP. This part of the textbook presumes no knowledge on the part of the reader about NLP or linguistics. It will, therefore, provide all the basic information needed to begin working with texts in more robust ways. The reader will learn about two different approaches to NLP, specifically rules-based (heuristics) and machine learning-based. Both serve different functions and should be used in different situations. By the end of this part, the reader will have a basic understanding of each and know when to use them. The final chapter of this part of the textbook will look at a real-world problem, creating a rules-based heuristic pipeline to identify and extract specific types of entities from texts.\n",
    "\n",
    "Part Four of the textbook continues examining text analysis and shifts focus to topic modeling, a rather vogue method in the humanities. This part of the textbook will introduce students to the older approaches to topic modeling, specifically Latent Dierlicht Allocation (LDA) topic modeling so that they will have an understanding of the basic concepts and the history of the field. In Chapter 3, the reader will be introduced to the newer approaches to topic modeling using machine learning. Again, no knowledge about machine learning will be presumed on the part of the reader. For this portion of the textbook, the reader will be introduced to Top2Vec.\n",
    "\n",
    "Part Five of the textbook will introduce the reader to app development with the Streamlit library. Readers will gain an understanding of the basics of Streamlit and how to leverage its components to create custom apps within just a few hours that can be hosted in the cloud. The purpose of this part is to help the reader take an idea from concept to reality in as short of time as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba436a2a-06c3-45ca-b559-aa43593e0ac1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
