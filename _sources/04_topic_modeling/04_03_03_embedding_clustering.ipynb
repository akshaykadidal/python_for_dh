{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613bae22-5138-407f-85c3-89e00a8d7ab3",
   "metadata": {},
   "source": [
    "# <center>Embedding, Flattening, and Clustering</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720c9014-f185-4ac0-ac7c-52d58b0d5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a936f-5990-4c84-90ab-6a52519fcb35",
   "metadata": {},
   "source": [
    "Before we begin leveraging advanced transformer-based topic modeling libraries, like Top2Vec, we should have a good understanding about how they work. Top2Vec leverages three libraries: Sentence Transformers, UMAP, and HDBScan. Here, we will explore each of these so that the reader will have a basic understanding of the theory and methods behind Top2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d9c08c-9da5-4d4c-a5b9-95e3aecdcec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>Last</th>\n",
       "      <th>First</th>\n",
       "      <th>Description</th>\n",
       "      <th>Place</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Homeland</th>\n",
       "      <th>Province</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "      <th>HRV</th>\n",
       "      <th>ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AARON</td>\n",
       "      <td>Thabo Simon</td>\n",
       "      <td>An ANCYL member who was shot and severely inju...</td>\n",
       "      <td>Bethulie</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orange Free State</td>\n",
       "      <td>25.97552</td>\n",
       "      <td>-30.50329</td>\n",
       "      <td>shoot|injure</td>\n",
       "      <td>ANC|ANCYL|Police|SAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectId   Last        First  \\\n",
       "0         1  AARON  Thabo Simon   \n",
       "\n",
       "                                         Description     Place      Yr  \\\n",
       "0  An ANCYL member who was shot and severely inju...  Bethulie  1991.0   \n",
       "\n",
       "  Homeland           Province      Long       Lat           HRV  \\\n",
       "0      NaN  Orange Free State  25.97552 -30.50329  shoot|injure   \n",
       "\n",
       "                    ORG  \n",
       "0  ANC|ANCYL|Police|SAP  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/trc.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a9a627-d6a7-42a8-812c-2cf97c4b3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.Description.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be32817-af93-4868-b9f1-836e127b0ad1",
   "metadata": {},
   "source": [
    "## Embedding the Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215006e-f872-41ff-b54d-eea4dff8a639",
   "metadata": {},
   "source": [
    "The first step in using transformers in topic modeling is to convert the text into a vector. We met vectors when we explored LDA topic modeling in the previous chapter. Arrays for LDA topic modeling were rooted in a TF-IDF index. This index, while computationally light, did not retain semantic meaning or word order.\n",
    "\n",
    "When we are working with transformers, we can create a vector for each document in our dataset. This vector is not an index of the words used, rather it is an embedding for the entire document that contains its semantic usages of words. It also preserves in this same vector space the word order to a degree. This document vector is similar to the word vector that we met in Part Three of this textbook. Instead of embedding a single word, however, the entire document receives an embedding. This allows us to mathematically compare documents across an entire corpus.\n",
    "\n",
    "To convert our documents into vectors, we first need a transformer model. Fortunately, the Sentence Transformer library from HuggingFace allows us to easily load robust pre-trained language models. In our case, we will be using the `all-MiniLM-L6-v2` model. We can load this model by calling the Sentence Transformer class from the sentence_transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4464e80d-ecff-42d1-a890-7c30371d2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f29d6-ffc0-4750-b824-a39ab9f5120c",
   "metadata": {},
   "source": [
    "Once our model class is created, we can use the `.encode()` method. This method will encode all the documents that we pass to it. In our case, this is the approximately 22,000 descriptions from the TRC dataset. The `.encode()` method takes a single mandatory argument, a list of data to embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732055a3-ce5e-4486-81ef-ec4d61492456",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aebb04-0f5c-4c3b-81e6-9dfa65cbfdcc",
   "metadata": {},
   "source": [
    "Now that we have the vectors for each document, let's examine one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "923ce7b0-9c1a-4a05-84f7-a1a7e4ea3c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07123438,  0.00332592, -0.05571467,  0.08363085,  0.09066872,\n",
       "        0.055036  ,  0.08029196,  0.0137071 ,  0.05912024,  0.06226279],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dde0a6-bea0-4243-aca6-1350562a22e5",
   "metadata": {},
   "source": [
    "As we can see, this looks remarkably similar to our word embeddings. While this is useful for examining mathematically comparing the similarity between documents, it can be difficult to parse this numerical data visually. For this reason, it is useful to flatten the data into 2 or 3 dimensions. This allows the data to be graphed. In the previous chapter, we learned how to flatten data with PCA. In this chapter, we will meet a new dimensionality reduction algorithm, UMAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181f598-e80b-41c1-830f-f5a7360b64db",
   "metadata": {},
   "source": [
    "## Flattening the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa219641-6b20-4c14-b897-0c2c05590ae3",
   "metadata": {},
   "source": [
    "UMAP has gained popularity in recent years as a quick, effectively, and fairly accurate way to represent higher dimensional data in lower dimensions. In Python, we can access the UMAP algorithm through the UMAP library which can be installed with pip by typing the following command:\n",
    "\n",
    "`pip install umap-learn`\n",
    "\n",
    "Note the `-learn` after `umap`. This is very important as `umap` is an entirely different library.\n",
    "\n",
    "Once you have installed UMAP correctly, you can access the `UMAP` class. This will take several parameters that can be adjusted to yield different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7bb3dea-1752-4dfd-8c04-6ea3b797f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_proj = umap.UMAP(n_neighbors=10,\n",
    "                          min_dist=0.01,\n",
    "                          metric='correlation').fit_transform(doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39809f8d-95e8-4a52-9f48-81a27e3be5c5",
   "metadata": {},
   "source": [
    "## Isolating Clusters with HDBScan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73657b7a-c68c-40d0-b3a6-20f0d13b99d3",
   "metadata": {},
   "source": [
    "Once our data has been flattened, we can automatically identify the number of clusters within it and assign documents to each cluster with the HDBScan algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d7e2a74-ffb2-434e-8898-73be928a8d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355\n"
     ]
    }
   ],
   "source": [
    "hdbscan_labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(umap_proj)\n",
    "print(len(set(hdbscan_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63034bbd-f454-4a62-a3a9-6b50620dee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>Last</th>\n",
       "      <th>First</th>\n",
       "      <th>Description</th>\n",
       "      <th>Place</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Homeland</th>\n",
       "      <th>Province</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "      <th>HRV</th>\n",
       "      <th>ORG</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AARON</td>\n",
       "      <td>Thabo Simon</td>\n",
       "      <td>An ANCYL member who was shot and severely inju...</td>\n",
       "      <td>Bethulie</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orange Free State</td>\n",
       "      <td>25.97552</td>\n",
       "      <td>-30.50329</td>\n",
       "      <td>shoot|injure</td>\n",
       "      <td>ANC|ANCYL|Police|SAP</td>\n",
       "      <td>3.326068</td>\n",
       "      <td>6.641037</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectId   Last        First  \\\n",
       "0         1  AARON  Thabo Simon   \n",
       "\n",
       "                                         Description     Place      Yr  \\\n",
       "0  An ANCYL member who was shot and severely inju...  Bethulie  1991.0   \n",
       "\n",
       "  Homeland           Province      Long       Lat           HRV  \\\n",
       "0      NaN  Orange Free State  25.97552 -30.50329  shoot|injure   \n",
       "\n",
       "                    ORG         x         y  topic  \n",
       "0  ANC|ANCYL|Police|SAP  3.326068  6.641037     -1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"x\"] = umap_proj[:, 0]\n",
    "df[\"y\"] = umap_proj[:, 1]\n",
    "df[\"topic\"] = hdbscan_labels\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a95eb1-fb3d-400b-bde0-638c01c89816",
   "metadata": {},
   "source": [
    "## Analyzing the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c16b7-6109-4fcd-83fa-8289c55ec6ee",
   "metadata": {},
   "source": [
    "Now that we have the labels loaded into our DataFrame, we can use Pandas to interrogate that data. Let's grab a topic and examine it. Here, we will examine topic 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbda2a58-6608-4283-ba2f-80b914c6b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Dikwankwetla National Party (DNP) supporter and member of the QwaQwa parliament, had his house burnt down in Botshabelo, near Bloemfontein, on 19 August 1987. His home was again petrol-bombed in June 1990.\n",
      "\n",
      "A Dikwankwetla National Party (DNP) supporter who had her house burnt down by UDF supporters in Botshabelo, near Bloemfontein, on 16 July 1989, allegedly because of her support for the DNP.\n",
      "\n",
      "A local councillor and member of the Dikwankwetla National Party (DNP) who had his house burnt down by unidentified persons in Winburg, OFS, on 30 March 1990, allegedly because of his support for the DNP.\n",
      "\n",
      "A councilor and a member of the Dikwankwetla National Party (DNP) who was seriously injured when he was stabbed, beaten and burnt by ANC supporters in Botshabelo, near Bloemfontein, on 29 January 1990. DNP members were frequently attacked at this time, allegedly because of the party’s support for the QwaQwa homeland government.\n",
      "\n",
      "A supporter of the Dikwankwetla National Party (DNP) who lost her home in an arson attack and was burnt when petrol  was thrown at her and she was set alight by ANC supporters in Botshabelo, near Bloemfontein, on 29 January 1990. DNP members were frequently attacked at this time, allegedly because of the party’s support for the QwaQwa homeland government.\n",
      "\n",
      "He had his house and shop in Botshabelo, near Bloemfontein, damaged in an arson attack by unidentified persons in 1977, allegedly because he did not support the Dikwankwetla National Party (DNP). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in df.loc[df.topic == 100].Description.tolist():\n",
    "    print(d)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a3e04-6fd6-4b3d-af1d-012fe705101f",
   "metadata": {},
   "source": [
    "Notice that topic 100 has 6 different documents in it. They are all a bit different, but clearly match in a few ways. First, they all involve the Dikwankwetla National Party (DNP). Second, they all involve the concept of arson or burning in some way. In some cases, this is to physical property, but in others it is to persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df494a-9c08-4b27-a2a4-d963d98c287b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
